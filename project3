import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import MinMaxScaler
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense
from sklearn.metrics import mean_squared_error
import matplotlib.pyplot as plt

# --- Configuration ---
DATA_FILE = 'energy_data.csv'  # Replace with your data file path
TIMESTAMP_COL = 'timestamp'
CONSUMPTION_COL = 'consumption'
TEST_SIZE = 0.2
N_STEPS = 24  # Number of previous time steps to use for prediction
LSTM_UNITS = 50
EPOCHS = 10
BATCH_SIZE = 32

# --- 1. Data Loading and Preprocessing ---
def load_and_preprocess_data(file_path, timestamp_col, consumption_col):
    """Loads data, handles missing values, sorts, and splits into train/test."""
    try:
        data = pd.read_csv(file_path, index_col=timestamp_col, parse_dates=True)
    except FileNotFoundError:
        print(f"Error: File not found at {file_path}")
        return None, None

    data.sort_index(inplace=True)
    data.fillna(method='ffill', inplace=True)  # Handle missing values

    train_data, test_data = train_test_split(data[[consumption_col]], test_size=TEST_SIZE, shuffle=False)

    scaler = MinMaxScaler()
    train_data['scaled_consumption'] = scaler.fit_transform(train_data[[consumption_col]])
    test_data['scaled_consumption'] = scaler.transform(test_data[[consumption_col]])

    return train_data, test_data, scaler

# --- 2. Create Sequences for Time Series Forecasting ---
def create_sequences(data, n_steps, consumption_col='scaled_consumption'):
    """Creates sequences of data for time series prediction."""
    X, y = [], []
    for i in range(len(data) - n_steps):
        X.append(data[i:(i + n_steps)][consumption_col].values)
        y.append(data.iloc[i + n_steps][consumption_col])
    return np.array(X), np.array(y)

# --- 3. Build and Train the LSTM Model ---
def build_lstm_model(n_steps, lstm_units):
    """Builds a simple LSTM model."""
    model = Sequential()
    model.add(LSTM(lstm_units, activation='relu', input_shape=(n_steps, 1)))
    model.add(Dense(1))
    model.compile(optimizer='adam', loss='mse')
    return model

def train_model(model, X_train, y_train, epochs, batch_size, verbose=0):
    """Trains the LSTM model."""
    model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, verbose=verbose)
    return model

# --- 4. Make Predictions and Evaluate ---
def make_predictions(model, X_test, scaler):
    """Makes predictions using the trained model and inverse transforms the results."""
    y_pred_scaled = model.predict(X_test)
    y_pred = scaler.inverse_transform(y_pred_scaled)
    return y_pred

def evaluate_model(y_true, y_pred):
    """Evaluates the model using Mean Squared Error and Root Mean Squared Error."""
    mse = mean_squared_error(y_true, y_pred)
    rmse = np.sqrt(mse)
    print(f'Mean Squared Error: {mse:.4f}')
    print(f'Root Mean Squared Error: {rmse:.4f}')
    return mse, rmse

# --- 5. Visualization ---
def plot_predictions(test_data, y_true, y_pred, consumption_col):
    """Plots the actual vs. predicted consumption."""
    plt.figure(figsize=(12, 6))
    plt.plot(test_data.index[N_STEPS:], y_true, label='Actual Consumption')
    plt.plot(test_data.index[N_STEPS:], y_pred, label='Predicted Consumption')
    plt.xlabel('Timestamp')
    plt.ylabel('Energy Consumption')
    plt.title('Energy Consumption Prediction')
    plt.legend()
    plt.show()

# --- Main Execution ---
if __name__ == "__main__":
    train_data, test_data, scaler = load_and_preprocess_data(DATA_FILE, TIMESTAMP_COL, CONSUMPTION_COL)

    if train_data is not None and test_data is not None and scaler is not None:
        X_train, y_train = create_sequences(train_data, N_STEPS)
        X_test, y_test = create_sequences(test_data, N_STEPS)

        # Reshape input for LSTM: [samples, time steps, features]
        X_train = X_train.reshape((X_train.shape[0], X_train.shape[1], 1))
        X_test = X_test.reshape((X_test.shape[0], X_test.shape[1], 1))

        model = build_lstm_model(N_STEPS, LSTM_UNITS)
        trained_model = train_model(model, X_train, y_train, EPOCHS, BATCH_SIZE)

        y_pred = make_predictions(trained_model, X_test, scaler)
        y_true_original = scaler.inverse_transform(y_test.reshape(-1, 1))

        evaluate_model(y_true_original, y_pred)
        plot_predictions(test_data, y_true_original, y_pred, CONSUMPTION_COL)

        print("Energy consumption prediction complete.")

# --- Further Considerations (Not Implemented in this basic code) ---
# - Integration with smart grid infrastructure (real-time data ingestion, API calls, etc.)
# - More sophisticated model architectures (e.g., multiple LSTM layers, attention mechanisms)
# - Feature engineering (incorporating weather data, time-based features, etc.)
# - Hyperparameter tuning
# - Handling seasonality and trends more explicitly (e.g., using SARIMA or more complex neural networks)
# - Anomaly detection
# - Real-time prediction and deployment strategies
